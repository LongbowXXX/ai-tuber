# AI リテラシー: 高度な戦略とセキュリティプロトコル

> **「コードを書く人から、意図を設計する人へ」**

`README.md` では、AI をパートナーとして扱う基本姿勢を学びました。このドキュメントは、AI 能力を最大化する **Terraformer 標準プロンプティング戦略（SSG）** と、リスクを管理する **防御プロトコル** を定義します。

---

## 🧠 1. 構造より入力（SSG フレームワーク）

現代の AI モデル（Gemini 3 Pro、GPT-5.2 など）は膨大なコンテキストを処理できます。「短くするために情報を要約する」という古い知恵は捨て、**「一次ソースをそのまま十分に提供する」** というスタイルへ移行します。

### 3S 原則（Terraformer Standard）

コンテキスト提供の 3 原則:

1.  **Specific（具体的）**:
    - "it's weird" ではなく "it returns error code 500" のように言う。
2.  **Sufficient（十分）**:
    - **重要**: 長文を恐れない。情報を削るのではなく、ログやコードを丸ごと貼る。
    - AI にとっては「情報不足」の害が、「情報過多（ノイズ）」よりはるかに大きい。
3.  **Source-based（ソース基盤）**:
    - 自分の言葉で説明しない。エラーログ、実コード、仕様などの「一次ソース（Source）」をそのまま提示する。

### S.S.G. フレームワーク

Terraformer が推奨するプロンプト構造です。「Situation」と「Source」が十分なら、「Goal」は 1 行で足ります。

1.  **Situation**
    - 「何が起きているか」についての一次情報。
    - エラーログ、コンソール出力などを要約せず貼る。
2.  **Source**
    - `#file` や `@workspace` を使って、関連ファイル、設定ファイル、仕様を添付する。
    - 迷ったら「少なめ」より「多め」。
3.  **Goal**
    - 「何をしたいか」を簡潔に宣言する。
    - 例: "Fix this error." / "Write a test case for this logic."

---

## 🛡️ 2. 防御的 AI プログラミング（リスク管理）

AI は確率的に「もっともらしい嘘」をつく機械です。次のリスクを理解し、防御的に開発してください。

### 🚫 「Vibe Coding」を禁止する

**Vibe Coding** とは、ロジックを理解しないまま「動いていそう（Good Vibes）」という雰囲気だけで AI 生成コードを採用する行為です。

- **ルール**: 自分で説明できないコードを 1 行たりともコミットしてはならない。

### ☠️ Slopsquatting（パッケージの幻覚）

AI は「ハルシネーション」として存在しないパッケージ名（例: `fast-json-secure`）を提案することがあります。攻撃者は「AI が提案しがちな名前」を予測し、npm や PyPI に登録してマルウェアを仕込むことがあります（**Slopsquatting**）。

- **🚨 クリティカルルール**: AI が `npm install` や `import` を提案したら、**必ずブラウザでパッケージを検索し、公式で実在することを確認する。** 未検証パッケージの導入はサプライチェーン攻撃に直結します。

### 🛡️ セキュリティチェックリスト

- **SQL インジェクション**: 生 SQL を連結していないか？（プレースホルダ/ORM の使用を強制する）
- **シークレット**: API キーがハードコードされていないか？
- **情報漏洩**: プロンプトへ PII（個人識別情報）を入力していないか？

---

## 📝 3. Spec-Driven Development（SDD）

"Vibe Coding" を防ぐ最良の方法は、コードを書かせる前に **仕様（Specs）** を書くことです。

### ワークフロー

1.  **仕様を書く**: 実装したい機能の要件を Markdown（例: `specs/login.md`）に書く。Mermaid 図を含めるとより効果的。
2.  **コンテキストを与える**: 仕様を Copilot に読み込ませる（`#file`）。
3.  **生成する**: "Implement specifically according to `#login.md`." と指示する。

これにより、AI は「確率的な当て推量」ではなく「明確な真実（Ground Truth）」に基づいてコードを生成でき、論理破綻を大幅に減らせます。

---

## 🏗️ 4. コンテキストエンジニアリング（脳を使う）

Terraformer はすでにプロジェクトの「記憶」をエンジニアリングしています。あなたの仕事はそれを **活用** することです。

### `AGENTS.md`（中央脳）

このプロジェクトには、AI コンテキストの真実（source of truth）として機能する `AGENTS.md` ファイルがあります。

- **役割**: プロジェクトのアーキテクチャ、技術スタック、コーディング標準を定義する。
- **アクション**: **読む。** 暗記は不要ですが、AI が従おうとしているルールを把握する必要があります。AI がミスしたら `AGENTS.md` が古くないか確認します。

---

**"Trust, but Verify."**
あなたには、AI に十分な情報（Source）を与え、出力（Code）を厳格に検証する「オーケストレーター」として振る舞うことが求められます。

---

## 🤝 5. AI 協働ワークフロー

これらの戦略の潜在能力を最大化するため、構造化された協働プロセスに従います。

### **Terraformer 標準ワークフロー**

各フェーズ（要件、設計、実装、検証、リリース）における AI と人間の役割分担を明確化する標準ワークフローを定義しています。

- **ルール**: タスクを進めるときは常に [AI Collaborative Model](../../workflows/workflow.md) に従う。
- **キー概念**:
  - **Process in Issue**: 議論と意思決定は GitHub Issues に記録する。
  - **Result in Git**: 最終成果物（コード、仕様）は Git で管理する。
