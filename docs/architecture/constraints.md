<!-- このドキュメントは .github/prompts/doc-sync.prompt.md によって生成および更新されています -->

# 制約・落とし穴・非機能要件

## 1. 非機能要件と考慮事項

- **リアルタイム性**: `stage-director` から `vtube-stage` へのコマンド送信、および `vtube-stage` での VRM モデル更新は、スムーズなアニメーションを実現するために低遅延である必要があります。WebSocket はこの要件に適しています。AI の応答生成 (`vtuber-behavior-engine`) は最も遅延が大きいボトルネックとなる可能性があり、最適化が必要です。
- **パフォーマンス**: `vtube-stage` での Three.js レンダリングは、特に複雑なモデルやエフェクトを使用する場合、効率的である必要があります。GPU アクセラレーションを活用し、不要な再レンダリングを避けることが重要です。
- **拡張性**:
  - AI 能力: ADK/MCP の採用により、新しいツールやエージェントを `vtuber-behavior-engine` に追加して機能を拡張することが容易になります。
  - キャラクター: 新しい VRM モデルを追加し、関連する設定（`stage-director` での感情マッピングなど）を行うことで、複数のキャラクターをサポートできます。
- **保守性**: コンポーネント間の明確な分離と、ADK による構造化された AI ロジックの実装は、システムの保守性を向上させます。各コンポーネントは独立してテストおよびデプロイできます。
- **エラーハンドリング**: 各コンポーネントは、通信エラー（WebSocket 切断、OBS 接続失敗）や内部エラー（AI モデルエラー、レンダリングエラー）を適切に処理し、可能な限り回復するか、明確なエラーログを出力する必要があります。

## 2. デプロイメントアーキテクチャ (概要)

- **AI Backend**: `vtuber-behavior-engine` と `stage-director` は Python アプリケーションであり、同じマシンまたは別々のマシン（コンテナ化推奨）で実行できます。
- **Frontend**: `vtube-stage` は Web アプリケーションであり、ローカルマシン上のブラウザで実行されます。
- **通信**:
  - `stage-director` と `vtube-stage` はローカルネットワーク経由で WebSocket で通信します。
  - `vtube-stage` と OBS Studio はローカルネットワーク経由で `obs-websocket` で通信します（将来対応）。

## 3. 既知の制約と落とし穴

- **認証/認可がない**: `stage-director` の WebSocket (`/ws`) と MCP(SSE) は、現状ローカル用途を想定したシンプル構成で、アクセス制御がありません。
- **単一接続前提の挙動**: コマンドキューはプロセス全体で共有され、接続クライアントが複数ある場合の配信ポリシーが明示されていません。
- **同期/順序の制約**: `speak` ツールは `speakEnd` を受けるまで待機します。`vtube-stage` 側で `speakEnd` を送らない／落ちると、AI 側がブロックする可能性があります。
- **フロントエンド環境変数**: `vtube-stage` の変数名は `DIRECTOR` ではなく **`DIRECTER`** になっている点に注意してください。
- **OBS 連携**: obs-websocket による OBS 制御は現状未実装です（ウィンドウキャプチャ前提）。
- **データ検証**: 片側でコマンド型を拡張した場合、もう片側の型/バリデータも更新が必要です。
